{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MODNet-quick-inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peace-and-harmony/image-matting/blob/main/notebooks/modnet_quick_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlARSYHGHgev"
      },
      "source": [
        "# MODNet quick inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3t-jsyrtl7w"
      },
      "source": [
        "## 1. Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNQdGow_YlPL"
      },
      "source": [
        "%%capture\n",
        "!git clone https://github.com/peace-and-harmony/image-matting.git\n",
        "!git clone https://github.com/ZHKKKe/MODNet.git\n",
        "!pip install --upgrade pillow"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaXFIdEpulEi"
      },
      "source": [
        "## 2. Upload Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nog7bf3nfG6Y"
      },
      "source": [
        "<p align=\"justify\">Upload clothing images to extract foreground object (only PNG and JPG format are supported):</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_3jhVwQu3-P"
      },
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# clean and rebuild the image folders\n",
        "input_folder = '/content/input'\n",
        "if os.path.exists(input_folder):\n",
        "  shutil.rmtree(input_folder)\n",
        "os.makedirs(input_folder)\n",
        "\n",
        "output_folder = '/content/output/'\n",
        "if os.path.exists(output_folder):\n",
        "  shutil.rmtree(output_folder)\n",
        "os.makedirs(output_folder)\n",
        "\n",
        "# upload images (PNG or JPG)\n",
        "image_names = list(files.upload().keys())\n",
        "for image_name in image_names:\n",
        "  shutil.move(image_name, os.path.join(input_folder, image_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vel21EBZmwDZ"
      },
      "source": [
        "## 3. Quick inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWyzIEM7j3Lw"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from MODNet.src.models.modnet import MODNet\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  # define image to tensor transform\n",
        "  im_transform = transforms.Compose(\n",
        "      [\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "      ]\n",
        "  )\n",
        "  if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print('using gpu!')\n",
        "  else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "  # create MODNet and load the pre-trained ckpt\n",
        "  state = torch.load('/content/image-matting/pretrained_weights/checkpoint.pth', map_location=device)\n",
        "  modnet = MODNet(backbone_pretrained=False)\n",
        "  modnet = nn.DataParallel(modnet)\n",
        "  modnet.load_state_dict(state['state_dict'])\n",
        "\n",
        "  # inference images\n",
        "  im_names = os.listdir(input_folder)\n",
        "  for im_name in im_names:\n",
        "    print('Process image: {0}'.format(im_name))\n",
        "    # read image\n",
        "    im = Image.open(os.path.join(input_folder, im_name))\n",
        "    # unify image channels to 3\n",
        "    im = np.asarray(im)\n",
        "    if len(im.shape) == 2:\n",
        "        im = im[:, :, None]\n",
        "    if im.shape[2] == 1:\n",
        "        im = np.repeat(im, 3, axis=2)\n",
        "    elif im.shape[2] == 4:\n",
        "        im = im[:, :, 0:3]\n",
        "    # convert image to PyTorch tensor\n",
        "    im = Image.fromarray(im)\n",
        "    im = im_transform(im)\n",
        "\n",
        "    # add mini-batch dim\n",
        "    im = im[None, :, :, :]\n",
        "    im_b, im_c, im_h, im_w = im.shape\n",
        "\n",
        "    # resize image for input\n",
        "    im_rh, im_rw = (512, 512)\n",
        "    im = F.interpolate(im, size=(im_rh, im_rw), mode='area')\n",
        "\n",
        "    # inference\n",
        "    # _, _, matte = modnet(im.cuda(), False)\n",
        "    _, _, matte = modnet(im, False)\n",
        "\n",
        "    # resize and save matte\n",
        "    matte = F.interpolate(matte, size=(im_h, im_w), mode='area')\n",
        "    matte = matte[0][0].data.cpu().numpy()\n",
        "    matte_name = im_name.split('.')[0] + '.png'\n",
        "    Image.fromarray(((matte * 255).astype('uint8')), mode='L').save(os.path.join(output_folder, matte_name))\n",
        "\n",
        "def combined_display(image, matte):\n",
        "  # calculate display resolution\n",
        "  w, h = image.width, image.height\n",
        "  rw, rh = 800, int(h * 800 / (3 * w))\n",
        "  \n",
        "  # obtain predicted foreground\n",
        "  image = np.asarray(image)\n",
        "  if len(image.shape) == 2:\n",
        "    image = image[:, :, None]\n",
        "  if image.shape[2] == 1:\n",
        "    image = np.repeat(image, 3, axis=2)\n",
        "  elif image.shape[2] == 4:\n",
        "    image = image[:, :, 0:3]\n",
        "  matte = np.repeat(np.asarray(matte)[:, :, None], 3, axis=2) / 255\n",
        "  foreground = image * matte + np.full(image.shape, 255) * (1 - matte)\n",
        "  \n",
        "  # combine image, foreground, and alpha into one line\n",
        "  combined = np.concatenate((foreground, matte * 255, image), axis=1)\n",
        "  combined = Image.fromarray(np.uint8(combined)).resize((rw, rh))\n",
        "  return combined\n",
        "\n",
        "# visualize all images\n",
        "image_names = os.listdir(input_folder)\n",
        "for image_name in image_names:\n",
        "  matte_name = image_name.split('.')[0] + '.png'\n",
        "  image = Image.open(os.path.join(input_folder, image_name))\n",
        "  matte = Image.open(os.path.join(output_folder, matte_name))\n",
        "  display(combined_display(image, matte))\n",
        "  print(image_name, '\\n')\n",
        "# When inference using GPU, need to retart runtime of this cell."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIxoRx4MnivW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}