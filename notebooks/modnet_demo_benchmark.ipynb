{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modnet_demo_benchmark.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "426af06882d145f890c870eac6b251c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2d6fef8ba1e148e3a1a9e415f3986c7c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0cd6c66ba9a1448ab23cff88ea7690f0",
              "IPY_MODEL_e5628686eedc44d08baae09772be1864",
              "IPY_MODEL_4fb4fedebda54f939d79e5949c0d3e5e"
            ]
          }
        },
        "2d6fef8ba1e148e3a1a9e415f3986c7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0cd6c66ba9a1448ab23cff88ea7690f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c74d2569380149d485be180fe8f54a8e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d53100d100744e8db47a932ebd0aac60"
          }
        },
        "e5628686eedc44d08baae09772be1864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2605ae9fa6944e38b4dc12f74d96dcef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8c3df036cf0418488b7410ee09eba5f"
          }
        },
        "4fb4fedebda54f939d79e5949c0d3e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_728dcd01ac474fbbbbaf51f74d7d9990",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50/50 [00:56&lt;00:00,  1.11s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ac294919dcf4dc291cbcc19968cef3b"
          }
        },
        "c74d2569380149d485be180fe8f54a8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d53100d100744e8db47a932ebd0aac60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2605ae9fa6944e38b4dc12f74d96dcef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8c3df036cf0418488b7410ee09eba5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "728dcd01ac474fbbbbaf51f74d7d9990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ac294919dcf4dc291cbcc19968cef3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4eaedaafddc42458c916f69cd2c5e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_29f8249d449b489aa126747ac1ddde58",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7c200f29aa594f01b776fbb54410f06a",
              "IPY_MODEL_6f19a97e4716463fa57b07edd49b4047",
              "IPY_MODEL_1938c9c867b1447385d26f8c46536ea4"
            ]
          }
        },
        "29f8249d449b489aa126747ac1ddde58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c200f29aa594f01b776fbb54410f06a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e8aced510544d5aab70c4306cd4f1b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a9eb6c897614f30adfefce7f7a23eec"
          }
        },
        "6f19a97e4716463fa57b07edd49b4047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f3275d7b6eb44bf89af9e414869d05f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_edb0ad6dd3764ec7a710fead533fd545"
          }
        },
        "1938c9c867b1447385d26f8c46536ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f4a3f36be27448886af03b08a831c6c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50/50 [01:23&lt;00:00,  1.60s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c4197a10461c404f836cb4ce88b73b51"
          }
        },
        "1e8aced510544d5aab70c4306cd4f1b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a9eb6c897614f30adfefce7f7a23eec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f3275d7b6eb44bf89af9e414869d05f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "edb0ad6dd3764ec7a710fead533fd545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f4a3f36be27448886af03b08a831c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c4197a10461c404f836cb4ce88b73b51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82b9459b9b4945d396ee07bf91138f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_30d5cfca069f4fa7a09b5fb6afbf33ca",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2158d5de4e9c4fd99a78fc0982602670",
              "IPY_MODEL_51a82201983347309f4f6bc5f653902d",
              "IPY_MODEL_e45e8214526c4be38f7b6170b3d2b848"
            ]
          }
        },
        "30d5cfca069f4fa7a09b5fb6afbf33ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2158d5de4e9c4fd99a78fc0982602670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5573938c001c4db2b7834fcf024a9653",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01e4436b174f4746bb9d50ced8b82fd8"
          }
        },
        "51a82201983347309f4f6bc5f653902d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a6c450ed120427cb93022ddb6d9d15a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cf6ad4da47c4182b15bb08b4bfcf7a5"
          }
        },
        "e45e8214526c4be38f7b6170b3d2b848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_abdf6af436f44197bb805cbe1f51bce4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50/50 [00:58&lt;00:00,  1.17s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5ce8ebc1ef84a39a67a640b8c799879"
          }
        },
        "5573938c001c4db2b7834fcf024a9653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01e4436b174f4746bb9d50ced8b82fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a6c450ed120427cb93022ddb6d9d15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cf6ad4da47c4182b15bb08b4bfcf7a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abdf6af436f44197bb805cbe1f51bce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5ce8ebc1ef84a39a67a640b8c799879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peace-and-harmony/image-matting/blob/main/notebooks/modnet_demo_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHQ4sHigCXZu"
      },
      "source": [
        "<table align=\"left\"><td>\n",
        "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/Pronti-Beam/demos-experiments/blob/master/notebooks/u_2net_demo_benchmark_edition.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
        "  </a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://github.com/Pronti-Beam/blob/master/demos-experiments/notebooks/u_2net_demo_benchmark_edition.ipynb\">\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"https://www.linkedin.com/company/pronti-ai/?originalSubdomain=ca\">\n",
        "    <img width=128px src=\"https://miro.medium.com/max/3402/1*gPSJe7WqcC61cGyB0lxalQ.png\" /></a>\n",
        "</td><td>\n",
        "  <a target=\"_blank\"  href=\"http://beamdata.ca/\">\n",
        "    <img width=128px src=\"http://beamdata.ca/wp-content/uploads/2018/10/beamdata_web_logo.png\" /></a>\n",
        "</td></table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVcftw0vkMpp"
      },
      "source": [
        "# MODNet benchmark demo\n",
        "\n",
        "In this demo, the differece between Pytorch and ONNX runtime is compared.\n",
        "\n",
        "**Note** Use Runtime: CPU as base of the benchmark\n",
        "\n",
        " ---\n",
        "\n",
        "The model type and inference runtime are listed in the Table:\n",
        "\n",
        "Model name  | Inference type | Runtime per image (ms)\n",
        "-------------------|------------------|-----------------\n",
        "checkpoint.pth       | Pytorch  | 1302.6847\n",
        "checkpoint.onnx       | ONNX runtime    | 848.1648 \n",
        "checkpoint-simplified.onnx       | ONNX runtime     | 824.7533\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBYiSxafAUX9",
        "outputId": "a3da83ee-0869-487a-f559-e28fe3cbac07"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPoFHWr9H1YA"
      },
      "source": [
        "### Load the test dataset for inference runtime benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA3oJs-KdesI"
      },
      "source": [
        "%cd /content\n",
        "!ls /content/drive/MyDrive/Cropper\n",
        "!cp /content/drive/MyDrive/Cropper/cropper_validation.zip /content\n",
        "!unzip cropper_validation.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPD0WZUgd2Gl",
        "outputId": "2116e494-6c54-4670-cb6d-e90fcba7bc06"
      },
      "source": [
        "%cd /content/valid_validation\n",
        "!mkdir test_run\n",
        "!cp -r image test_run"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/valid_validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcFoyvUbaYJi",
        "outputId": "c1ea171a-7562-497e-8150-694e337253b9"
      },
      "source": [
        "import glob\n",
        "len(glob.glob('/content/valid_validation/mask/*.jpeg'))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1127"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s50xkUCNrVtz"
      },
      "source": [
        "#### Download the pre-trained MODNet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbWLbz7xd2BY",
        "outputId": "fe7dcf9f-f478-4329-dc95-ebdd4d766e14"
      },
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/ZHKKKe/MODNet.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'MODNet'...\n",
            "remote: Enumerating objects: 249, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 249 (delta 21), reused 24 (delta 9), pack-reused 206\u001b[K\n",
            "Receiving objects: 100% (249/249), 60.76 MiB | 26.11 MiB/s, done.\n",
            "Resolving deltas: 100% (83/83), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjJFG1GGzdKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94767862-8c0d-4fbc-a8ae-0438c94d0a8c"
      },
      "source": [
        "!mkdir -p /content/MODNet/test_data/test_human_images_results/\n",
        "%ls /content/MODNet/test_data/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mtest_human_images\u001b[0m/  \u001b[01;34mtest_human_images_results\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVJhJ0xn_Lb1"
      },
      "source": [
        "# Generate .onnx\n",
        "- Optimisation\n",
        "\n",
        "ValueError: Unsupported ONNX opset version: 13\n",
        "\n",
        "  - opset_version=12\n",
        "\n",
        "\n",
        "\n",
        "The next step should we decide to continue and pursuse this avenue would be to investigate whether or need this particular graph is rejected by TesnorRT's onnnx parser, or alternatively coreml etc should you want to deploy directly on the edge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYHe2Pfrqp8z"
      },
      "source": [
        "#### install the requirements for converting MODNet to .onnx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN4qhpiAtt_2"
      },
      "source": [
        "%cd /content/MODNet\n",
        "!pip install -r onnx/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl1o8xvxdrA_",
        "outputId": "868fb73d-9f81-4e78-b7c3-51559bc9ad02"
      },
      "source": [
        "%ls /content/drive/MyDrive/Beamdata-Pronti/modelsv2/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_bcev2_itr_101297_tar_29.000000.pth  _bcev2_itr_41916_tar_12.000000.pth\n",
            "_bcev2_itr_104790_tar_30.000000.pth  _bcev2_itr_45409_tar_13.000000.pth\n",
            "_bcev2_itr_10479_tar_3.000000.pth    _bcev2_itr_48902_tar_14.000000.pth\n",
            "_bcev2_itr_108283_tar_31.000000.pth  _bcev2_itr_52395_tar_15.000000.pth\n",
            "_bcev2_itr_111776_tar_32.000000.pth  _bcev2_itr_55888_tar_16.000000.pth\n",
            "_bcev2_itr_115269_tar_33.000000.pth  _bcev2_itr_59381_tar_17.000000.pth\n",
            "_bcev2_itr_118762_tar_34.000000.pth  _bcev2_itr_62874_tar_18.000000.pth\n",
            "_bcev2_itr_122255_tar_35.000000.pth  _bcev2_itr_66367_tar_19.000000.pth\n",
            "_bcev2_itr_125748_tar_36.000000.pth  _bcev2_itr_69860_tar_20.000000.pth\n",
            "_bcev2_itr_129241_tar_37.000000.pth  _bcev2_itr_6986_tar_2.000000.pth\n",
            "_bcev2_itr_132734_tar_38.000000.pth  _bcev2_itr_73353_tar_21.000000.pth\n",
            "_bcev2_itr_136472_tar_39.000000.pth  _bcev2_itr_76846_tar_22.000000.pth\n",
            "_bcev2_itr_13972_tar_4.000000.pth    _bcev2_itr_80339_tar_23.000000.pth\n",
            "_bcev2_itr_140210_tar_40.000000.pth  _bcev2_itr_83832_tar_24.000000.pth\n",
            "_bcev2_itr_143948_tar_41.000000.pth  _bcev2_itr_87325_tar_25.000000.pth\n",
            "_bcev2_itr_147686_tar_42.000000.pth  _bcev2_itr_90818_tar_26.000000.pth\n",
            "_bcev2_itr_151424_tar_43.000000.pth  _bcev2_itr_94311_tar_27.000000.pth\n",
            "_bcev2_itr_155162_tar_44.000000.pth  _bcev2_itr_97804_tar_28.000000.pth\n",
            "_bcev2_itr_158900_tar_45.000000.pth  \u001b[0m\u001b[01;34mlogs\u001b[0m/\n",
            "_bcev2_itr_17465_tar_5.000000.pth    \u001b[01;34mmodelsv10log\u001b[0m/\n",
            "_bcev2_itr_20958_tar_5.000000.pth    \u001b[01;34mmodelsv11log\u001b[0m/\n",
            "_bcev2_itr_20958_tar_6.000000.pth    \u001b[01;34mmodelsv12log\u001b[0m/\n",
            "_bcev2_itr_24451_tar_7.000000.pth    \u001b[01;34mmodelsv13log\u001b[0m/\n",
            "_bcev2_itr_27944_tar_8.000000.pth    \u001b[01;34mmodelsv1log\u001b[0m/\n",
            "_bcev2_itr_31437_tar_9.000000.pth    \u001b[01;34mmodelsv6log\u001b[0m/\n",
            "_bcev2_itr_34930_tar_10.000000.pth   \u001b[01;34mmodelsv7log\u001b[0m/\n",
            "_bcev2_itr_3493_tar_1.000000.pth     modnet-gpu.onnx\n",
            "_bcev2_itr_38423_tar_11.000000.pth   modnet-modelsv2-39-gpu.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nWFdRLAdUKr"
      },
      "source": [
        "!cp /content/drive/MyDrive/Beamdata-Pronti/modelsv2/_bcev2_itr_158900_tar_45.000000.pth /content/MODNet/pretrained/"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PTri6c92T5k"
      },
      "source": [
        "### Export to cpu-based .onnx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsPm-aBahFZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d16e0224-e399-4321-ecdb-9f0b46ac1c06"
      },
      "source": [
        "%ls /content/MODNet/pretrained/"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_bcev2_itr_158900_tar_45.000000.pth  modnet_photographic_portrait_matting.ckpt\n",
            "modnet-cpu.onnx                      README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WXqjpvkdQWSm",
        "outputId": "16cfa557-ded3-466e-86fc-cdcb3cee986f"
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v0-OxjbQesN",
        "outputId": "6ce78317-190a-4397-9f62-270b5abc5983"
      },
      "source": [
        "%ls /content/MODNet/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdemo\u001b[0m/  \u001b[01;34mdoc\u001b[0m/  \u001b[01;34monnx\u001b[0m/  \u001b[01;34mpretrained\u001b[0m/  README.md  \u001b[01;34msrc\u001b[0m/  \u001b[01;34mtest_data\u001b[0m/  \u001b[01;34mtorchscript\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvojg7EiRmTj",
        "outputId": "f04d33c7-475e-4ce1-d4f8-d99b22eb096b"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MODNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9vM8QjbDDVV",
        "outputId": "409d6948-7dfb-4c26-a79a-766fc3cda18d"
      },
      "source": [
        "%cd /content/MODNet\n",
        "\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from MODNet.src.models.modnet import MODNet\n",
        "from MODNet.onnx import modnet_onnx\n",
        "\n",
        "\n",
        "# general input\n",
        "input_name = '/content/MODNet/pretrained/_bcev2_itr_158900_tar_45.000000.pth'\n",
        "# check input arguments\n",
        "if not os.path.exists(input_name):\n",
        "    print('Cannot find checkpoint path: {0}'.format(ckpt_path))\n",
        "    exit()\n",
        "\n",
        "# define model & load checkpoint\n",
        "modnet = modnet_onnx.MODNet(backbone_pretrained=False)\n",
        "\n",
        "# prepare dummy_input\n",
        "batch_size = 1\n",
        "height = 512\n",
        "width = 512\n",
        "\n",
        "# dummy_input: input tensor x. The values in this can be random as long as it is the right type and size\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  print('using gpu!')\n",
        "  dummy_input = Variable(torch.randn(batch_size, 3, height, width)).cuda()\n",
        "  modnet = nn.DataParallel(modnet).cuda()\n",
        "\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print('using cpu')\n",
        "  dummy_input = Variable(torch.randn(batch_size, 3, height, width))\n",
        "  modnet = nn.DataParallel(modnet)\n",
        "\n",
        "state_dict = torch.load(input_name, map_location=device)\n",
        "modnet.load_state_dict(state_dict['state_dict'])\n",
        "modnet.eval() # set the model to inference mode\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  output_name = '/content/MODNet/pretrained/modnet-gpu.onnx'\n",
        "else:\n",
        "  output_name = '/content/MODNet/pretrained/modnet-45-cpu.onnx'\n",
        "\n",
        "\n",
        "# export to onnx model\n",
        "torch.onnx.export(\n",
        "    modnet.module, dummy_input, output_name, export_params = True, \n",
        "    input_names = ['input'], output_names = ['output'], \n",
        "    dynamic_axes = {'input': {0:'batch_size', 2:'height', 3:'width'}, 'output': {0: 'batch_size', 2: 'height', 3: 'width'}}, opset_version=12)\n",
        "\n",
        "%ls /content/MODNet/pretrained/"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MODNet\n",
            "using cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_bcev2_itr_158900_tar_45.000000.pth  modnet_photographic_portrait_matting.ckpt\n",
            "modnet-45-cpu.onnx                   README.md\n",
            "modnet-cpu.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQr0f_FH9ssu"
      },
      "source": [
        ".onnx is a binary protobuf file which contains both the network structure and parameters of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Usckjm4zaIPU"
      },
      "source": [
        "Save modnet-cpu.onnx to drive for further onnx simplifier later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIlQBBAy6PMh",
        "outputId": "a0b74b4d-0ec7-4398-ce9f-95f629898dbd"
      },
      "source": [
        "%ls /content/MODNet/pretrained/"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_bcev2_itr_158900_tar_45.000000.pth  modnet-gpu-simplified.onnx\n",
            "modnet-45-gpu.onnx                   modnet_photographic_portrait_matting.ckpt\n",
            "modnet-45-gpu-simplified.onnx        README.md\n",
            "modnet-gpu.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q57FWfFLZ0nJ"
      },
      "source": [
        "!cp /content/MODNet/pretrained/modnet-45-gpu-simplified.onnx /content/drive/MyDrive/Beamdata-Pronti/models/"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BdZ0os76W8N",
        "outputId": "efd9d6cf-dda8-4143-a57e-db4639ee4713"
      },
      "source": [
        "%ls /content/drive/MyDrive/Beamdata-Pronti/models/"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_bce_itr_101297_tar_29.000000.pth  _bce_itr_69860_tar_20.000000.pth\n",
            "_bce_itr_104790_tar_30.000000.pth  _bce_itr_6986_tar_2.000000.pth\n",
            "_bce_itr_10479_tar_3.000000.pth    _bce_itr_73353_tar_21.000000.pth\n",
            "_bce_itr_108283_tar_31.000000.pth  _bce_itr_76846_tar_22.000000.pth\n",
            "_bce_itr_111776_tar_32.000000.pth  _bce_itr_80339_tar_23.000000.pth\n",
            "_bce_itr_115269_tar_33.000000.pth  _bce_itr_83832_tar_24.000000.pth\n",
            "_bce_itr_13972_tar_4.000000.pth    _bce_itr_87325_tar_25.000000.pth\n",
            "_bce_itr_17465_tar_5.000000.pth    _bce_itr_90818_tar_26.000000.pth\n",
            "_bce_itr_20958_tar_6.000000.pth    _bce_itr_94311_tar_27.000000.pth\n",
            "_bce_itr_24451_tar_7.000000.pth    _bce_itr_97804_tar_28.000000.pth\n",
            "_bce_itr_27944_tar_8.000000.pth    \u001b[0m\u001b[01;34mlogs\u001b[0m/\n",
            "_bce_itr_31437_tar_9.000000.pth    mobilenetv2_human_seg.ckpt\n",
            "_bce_itr_34930_tar_10.000000.pth   modnet-45-gpu.onnx\n",
            "_bce_itr_3493_tar_1.000000.pth     modnet-45-gpu-simplified.onnx\n",
            "_bce_itr_38423_tar_11.000000.pth   modnet-cpu.onnx\n",
            "_bce_itr_41916_tar_12.000000.pth   modnet-cpu-onnx-simplified.plan\n",
            "_bce_itr_45409_tar_13.000000.pth   modnet-cpu-simplified.onnx\n",
            "_bce_itr_48902_tar_14.000000.pth   modnet-gpu.onnx\n",
            "_bce_itr_52395_tar_15.000000.pth   modnet-gpu-simplified.onnx\n",
            "_bce_itr_55888_tar_16.000000.pth   modnet.onnx\n",
            "_bce_itr_59381_tar_17.000000.pth   modnet_photographic_portrait_matting.ckpt\n",
            "_bce_itr_62874_tar_18.000000.pth   u2net-aug3-prontipedia-13-08-b4.onnx\n",
            "_bce_itr_66367_tar_19.000000.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUWFxFYN2KbU"
      },
      "source": [
        "### Output of PyTorch and ONNX match test\n",
        "  - trace-based means that it operates by executing your model once\n",
        "  - the output of PyTorch and ONNX Runtime runs match numerically with the given precision (rtol=1e-03 and atol=1e-05)\n",
        "  - onnx exporter is correct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enn0zowX2XSd",
        "outputId": "bb699809-e979-448d-fd33-5984f886d607"
      },
      "source": [
        "import onnxruntime\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Input to the model\n",
        "x = torch.randn(1, 3, 512, 512, requires_grad=True)\n",
        "torch_out = modnet(x)\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"/content/MODNet/pretrained/modnet-45-cpu.onnx\")\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results\n",
        "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-usZ1NZWjIe3"
      },
      "source": [
        "#ONNX Runtime inference\n",
        "\n",
        "Use converted checkpoint.onnx for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGuoVNB-kIR9",
        "outputId": "4adbf09b-7794-4acb-aab3-8e96899f37ef"
      },
      "source": [
        "!pip install onnxruntime\n",
        "!pip install onnx"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime) (1.15.0)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r36tSpntt8w",
        "outputId": "775dad29-964e-490b-f348-505e20ec312c"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "%cd /content/MODNet/\n",
        "img_name_list = glob.glob('/content/valid_validation/image/' + os.sep + '*')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MODNet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZAUsjNFeTZJ",
        "outputId": "b5179e6c-aa9d-40ab-8887-8a2c75245e4f"
      },
      "source": [
        "!mkdir -p /content/valid_validation/image/test_run\n",
        "!cp /content/valid_validation/image/* /content/valid_validation/image/test_run"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: -r not specified; omitting directory '/content/valid_validation/image/test_run'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9f8LoebHnd6"
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "val_data = \"/content/valid_validation/image\"\n",
        "\n",
        "TRANSFORM_IMG = transforms.Compose([\n",
        "     transforms.Resize((512, 512)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "val = torchvision.datasets.ImageFolder(val_data, transform=TRANSFORM_IMG)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "426af06882d145f890c870eac6b251c5",
            "2d6fef8ba1e148e3a1a9e415f3986c7c",
            "0cd6c66ba9a1448ab23cff88ea7690f0",
            "e5628686eedc44d08baae09772be1864",
            "4fb4fedebda54f939d79e5949c0d3e5e",
            "c74d2569380149d485be180fe8f54a8e",
            "d53100d100744e8db47a932ebd0aac60",
            "2605ae9fa6944e38b4dc12f74d96dcef",
            "e8c3df036cf0418488b7410ee09eba5f",
            "728dcd01ac474fbbbbaf51f74d7d9990",
            "1ac294919dcf4dc291cbcc19968cef3b"
          ]
        },
        "id": "FrYUTHMrGBRc",
        "outputId": "4225f3aa-2774-4529-dfae-5b77504f25f4"
      },
      "source": [
        "# ONNX Runtime Inference\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import onnxruntime as rt  \n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "n_runs = 50\n",
        "\n",
        "sess_options = rt.SessionOptions()\n",
        "\n",
        "sess_options.intra_op_num_threads = 4\n",
        "sess_options.execution_mode = rt.ExecutionMode.ORT_SEQUENTIAL\n",
        "sess_options.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "\n",
        "session = rt.InferenceSession('/content/MODNet/pretrained/modnet-45-cpu.onnx', sess_options=sess_options)\n",
        "\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "\n",
        "dynamic = False\n",
        "if dynamic:\n",
        "  bsize = (1,2,4,8,16,32,64)\n",
        "else:\n",
        "  bsize = (1,)\n",
        "\n",
        "start_full = time.time()\n",
        "for batch_size in bsize:\n",
        "    runtimes = []\n",
        "    for _ in tqdm(range(n_runs)):\n",
        "        dataloader = DataLoader(dataset=val, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        batch = next(iter(dataloader))\n",
        "        batch = tuple(t.to('cpu') for t in batch)\n",
        "\n",
        "        start = time.time()\n",
        "        pred = session.run([output_name], {input_name: batch[0].numpy()})[0]\n",
        "        end = time.time()\n",
        "        runtimes.append((end-start)*1000)\n",
        "\n",
        "    print(f\"inference cost for batch_size {batch_size}: {round(sum(runtimes)/len(runtimes), 4)} ms\")\n",
        "\n",
        "end_full = time.time()\n",
        "overall_cost = (end_full - start_full)\n",
        "print(f\"overall inference execution cost: {round(overall_cost, 4)} seconds\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "426af06882d145f890c870eac6b251c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inference cost for batch_size 1: 848.1648 ms\n",
            "overall inference execution cost: 56.2741 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3rK2S823gJ1"
      },
      "source": [
        "# Pytorch comparison\n",
        "Use pretrained checkpoint.pth via Pytorch for inference\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154,
          "referenced_widgets": [
            "d4eaedaafddc42458c916f69cd2c5e0b",
            "29f8249d449b489aa126747ac1ddde58",
            "7c200f29aa594f01b776fbb54410f06a",
            "6f19a97e4716463fa57b07edd49b4047",
            "1938c9c867b1447385d26f8c46536ea4",
            "1e8aced510544d5aab70c4306cd4f1b0",
            "3a9eb6c897614f30adfefce7f7a23eec",
            "f3275d7b6eb44bf89af9e414869d05f7",
            "edb0ad6dd3764ec7a710fead533fd545",
            "5f4a3f36be27448886af03b08a831c6c",
            "c4197a10461c404f836cb4ce88b73b51"
          ]
        },
        "id": "dlDVtHntg5aZ",
        "outputId": "13c303c9-e7f3-404e-aea5-d6bb0555b923"
      },
      "source": [
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "dynamic = False\n",
        "\n",
        "# load MODNet and pretrained checkpoint\n",
        "input_name = '/content/MODNet/pretrained/_bcev2_itr_158900_tar_45.000000.pth'\n",
        "# check input arguments\n",
        "if not os.path.exists(input_name):\n",
        "    print('Cannot find checkpoint path: {0}'.format(ckpt_path))\n",
        "    exit()\n",
        "\n",
        "# define model & load checkpoint\n",
        "modnet = modnet_onnx.MODNet(backbone_pretrained=False)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  print('using gpu!')\n",
        "  modnet = nn.DataParallel(modnet).cuda()\n",
        "\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  print('using cpu')\n",
        "  modnet = nn.DataParallel(modnet)\n",
        "\n",
        "state_dict = torch.load(input_name, map_location=device)\n",
        "modnet.load_state_dict(state_dict['state_dict'])\n",
        "modnet.eval() # set the model to inference mode\n",
        "\n",
        "if dynamic:\n",
        "  bsize = (1,2,4,8,16,32,64)\n",
        "else:\n",
        "  bsize = (1,)\n",
        "\n",
        "n_runs = 50\n",
        "\n",
        "start_full = time.time()\n",
        "for batch_size in bsize:\n",
        "    runtimes = []\n",
        "    for _ in tqdm(range(n_runs)):\n",
        "        dataloader = DataLoader(dataset=val, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        batch = next(iter(dataloader))\n",
        "        batch = tuple(t.to('cpu') for t in batch)\n",
        "\n",
        "        start = time.time()\n",
        "        matte = modnet(batch[0])\n",
        "        end = time.time()\n",
        "        runtimes.append((end-start)*1000)\n",
        "\n",
        "    print(f\"inference cost for batch_size {batch_size}: {round(sum(runtimes)/len(runtimes), 4)}ms\")\n",
        "\n",
        "end_full = time.time()\n",
        "overall_cost = (end_full - start_full)\n",
        "print(f\"overall inference execution cost: {round(overall_cost, 4)} seconds\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cpu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4eaedaafddc42458c916f69cd2c5e0b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inference cost for batch_size 1: 1302.6847ms\n",
            "overall inference execution cost: 83.5205 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqni2-P4oNoY"
      },
      "source": [
        "## ONNX Simplifier\n",
        "replaces the redundant operators with their constant outputs to simplify onnx model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTNR1UF31ybV"
      },
      "source": [
        "%cd /content/\n",
        "#Otherwise we get a random pad node error\n",
        "!pip3 install -U pip && pip3 install onnx-simplifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW_wteftpVpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0682450-626e-4093-dc71-90e86c2f7e3e"
      },
      "source": [
        "%ls /content/MODNet/pretrained/"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_bcev2_itr_158900_tar_45.000000.pth  modnet_photographic_portrait_matting.ckpt\n",
            "modnet-45-cpu.onnx                   README.md\n",
            "modnet-cpu.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A-6le-M_1pw",
        "outputId": "b1c4841d-eafd-4b3e-afdc-81b64e15e516"
      },
      "source": [
        "!python3 -m onnxsim /content/MODNet/pretrained/modnet-45-cpu.onnx /content/MODNet/pretrained/modnet-45-cpu-simplified.onnx --input-shape 1,3,512,512"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simplifying...\n",
            "Note: The input shape of the simplified model will be overwritten by the value of '--input-shape' argument. Pass '--dynamic-input-shape' if it is not what you want. Run 'python3 -m onnxsim -h' for details.\n",
            "Checking 0/3...\n",
            "Checking 1/3...\n",
            "Checking 2/3...\n",
            "Ok!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6QERFzNzLcn",
        "outputId": "2b884f62-26f0-4daf-dba6-1a7050b302cb"
      },
      "source": [
        "!du /content/MODNet/pretrained/modnet-gpu.onnx"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25284\t/content/MODNet/pretrained/modnet-gpu.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phYkYlgWzO4X",
        "outputId": "eefa109b-823b-4958-ccc5-e2467c1baf4f"
      },
      "source": [
        "!du /content/MODNet/pretrained/modnet-gpu-simplified.onnx"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25276\t/content/MODNet/pretrained/modnet-gpu-simplified.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "82b9459b9b4945d396ee07bf91138f98",
            "30d5cfca069f4fa7a09b5fb6afbf33ca",
            "2158d5de4e9c4fd99a78fc0982602670",
            "51a82201983347309f4f6bc5f653902d",
            "e45e8214526c4be38f7b6170b3d2b848",
            "5573938c001c4db2b7834fcf024a9653",
            "01e4436b174f4746bb9d50ced8b82fd8",
            "0a6c450ed120427cb93022ddb6d9d15a",
            "2cf6ad4da47c4182b15bb08b4bfcf7a5",
            "abdf6af436f44197bb805cbe1f51bce4",
            "c5ce8ebc1ef84a39a67a640b8c799879"
          ]
        },
        "id": "iyCN_DWK109c",
        "outputId": "e42cc692-2481-46cd-ff6a-f345cf592566"
      },
      "source": [
        "# ONNX Runtime Inference\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import onnxruntime as rt  \n",
        "import time\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "n_runs = 50\n",
        "\n",
        "sess_options = rt.SessionOptions()\n",
        "\n",
        "sess_options.intra_op_num_threads = 4\n",
        "sess_options.execution_mode = rt.ExecutionMode.ORT_SEQUENTIAL\n",
        "sess_options.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "\n",
        "# To enable model serialization and store the optimized graph to desired location.\n",
        "#sess_options.optimized_model_filepath = '/content/esnet/optimized/esnet.onnx'\n",
        "session = rt.InferenceSession('/content/MODNet/pretrained/modnet-45-cpu-simplified.onnx', sess_options=sess_options)\n",
        "\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "\n",
        "dynamic = False\n",
        "if dynamic:\n",
        "  bsize = (1,2,4,8,16,32,64)\n",
        "else:\n",
        "  bsize = (1,)\n",
        "\n",
        "start_full = time.time()\n",
        "for batch_size in bsize:\n",
        "    runtimes = []\n",
        "    for _ in tqdm(range(n_runs)):\n",
        "        dataloader = DataLoader(dataset=val, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "        batch = next(iter(dataloader))\n",
        "        batch = tuple(t.to('cpu') for t in batch)\n",
        "\n",
        "        start = time.time()\n",
        "        pred = session.run([output_name], {input_name: batch[0].numpy()})[0]\n",
        "        end = time.time()\n",
        "        runtimes.append((end-start)*1000)\n",
        "\n",
        "        #print(pred.shapredictions, bitmask = torch.max(pred_torch, 1)pe)\n",
        "    print(f\"inference cost for batch_size {batch_size}: {round(sum(runtimes)/len(runtimes), 4)} ms\")\n",
        "\n",
        "end_full = time.time()\n",
        "overall_cost = (end_full - start_full)\n",
        "print(f\"overall inference execution cost: {round(overall_cost, 4)} seconds\")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82b9459b9b4945d396ee07bf91138f98",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inference cost for batch_size 1: 824.7533 ms\n",
            "overall inference execution cost: 58.2651 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L-dog1Wufzj"
      },
      "source": [
        "## Model Visualization via Netron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITZ25KWstvlF",
        "outputId": "1b8224ce-9efc-4035-af8f-e03e78e28918"
      },
      "source": [
        "!pip install -q netron"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 37.1 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 122 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 153 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 163 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 194 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 204 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 235 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 245 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 286 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 307 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 317 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 327 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 348 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 358 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 389 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 399 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 430 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 440 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 460 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 471 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 481 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 501 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 512 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 522 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 542 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 552 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 583 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 593 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 614 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 624 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 634 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 655 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 665 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 675 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 696 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 706 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 716 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 727 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 737 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 747 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 757 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 768 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 778 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 788 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 798 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 808 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 819 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 829 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 839 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 849 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 860 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 870 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 880 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 890 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 901 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 911 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 921 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 931 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 942 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 952 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 962 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 972 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 983 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 993 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.0 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.0 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.0 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.0 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.2 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.3 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.3 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.3 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 8.3 MB/s \n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiZX44he1mtY",
        "outputId": "25c8f569-53e1-4351-9456-de454e0189cc"
      },
      "source": [
        "%ls /content/MODNet/pretrained/"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_bcev2_itr_158900_tar_45.000000.pth  modnet-gpu-simplified.onnx\n",
            "modnet-45-gpu.onnx                   modnet_photographic_portrait_matting.ckpt\n",
            "modnet-gpu.onnx                      README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCxWb7cfR4xN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "aa04fcfe-6222-445b-e8d9-e9ee99ec9fef"
      },
      "source": [
        "import netron\n",
        "import portpicker\n",
        "from google.colab import output\n",
        "\n",
        "port = portpicker.pick_unused_port()\n",
        "\n",
        "# Read the model file and start the netron browser.\n",
        "with output.temporary():\n",
        "  netron.start('/content/MODNet/pretrained/modnet-gpu.onnx', address=port, browse=True)\n",
        "\n",
        "output.serve_kernel_port_as_iframe(port, height='800')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    element.appendChild(iframe);\n",
              "  })(17125, \"/\", \"100%\", \"800\", false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "wwFtwVlg1tfm",
        "outputId": "4bd5e321-60a0-4229-a677-b99fe26946e2"
      },
      "source": [
        "import netron\n",
        "import portpicker\n",
        "from google.colab import output\n",
        "\n",
        "port = portpicker.pick_unused_port()\n",
        "\n",
        "# Read the model file and start the netron browser.\n",
        "with output.temporary():\n",
        "  netron.start('/content/MODNet/pretrained/modnet-gpu-simplified.onnx', address=port, browse=True)\n",
        "\n",
        "output.serve_kernel_port_as_iframe(port, height='800')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    element.appendChild(iframe);\n",
              "  })(22375, \"/\", \"100%\", \"800\", false, window.element)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTYUDtDs15cl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}